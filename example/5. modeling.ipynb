{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Modeling**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform:\n",
    "1. Forward Selection Procedure\n",
    "2. Best Model Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform Forward Selection Procedure**\n",
    "---\n",
    "Begin with null model (no predictors), then adds predictor that gives the greatest additional improvement to the model, one-at-a-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library for modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load configuration\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/credit_risk_dataset.csv',\n",
       " 'dataset_path': 'data/output/data.pkl',\n",
       " 'predictors_set_path': 'data/output/predictors.pkl',\n",
       " 'response_set_path': 'data/output/response.pkl',\n",
       " 'train_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'test_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'data_train_path': 'data/output/data_train.pkl',\n",
       " 'data_train_binned_path': 'data/output/data_train_binned.pkl',\n",
       " 'crosstab_list_path': 'data/output/crosstab_list.pkl',\n",
       " 'WOE_table_path': 'data/output/WOE_table.pkl',\n",
       " 'IV_table_path': 'data/output/IV_table.pkl',\n",
       " 'WOE_map_dict_path': 'data/output/WOE_map_dict.pkl',\n",
       " 'X_train_woe_path': 'data/output/X_train_woe.pkl',\n",
       " 'response_variable': 'loan_status',\n",
       " 'test_size': 0.3,\n",
       " 'num_columns': ['person_age',\n",
       "  'person_income',\n",
       "  'person_emp_length',\n",
       "  'loan_amnt',\n",
       "  'loan_int_rate',\n",
       "  'loan_percent_income',\n",
       "  'cb_person_cred_hist_length'],\n",
       " 'cat_columns': ['person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file'],\n",
       " 'missing_columns': ['person_emp_length_bin', 'loan_int_rate_bin'],\n",
       " 'num_of_bins': 4,\n",
       " 'num_of_cv': 10,\n",
       " 'scoring': 'recall',\n",
       " 'forward_models_path': 'models/forward_models.pkl',\n",
       " 'best_predictors_path': 'models/best_predictors_path.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_model_summary_path': 'models/best_model_summary.pkl',\n",
       " 'pdo': 20,\n",
       " 'score_ref': 300,\n",
       " 'odds_ref': 30,\n",
       " 'scorecards_path': 'models/scorecards.pkl',\n",
       " 'points_map_dict_path': 'models/points_map_dict.pkl',\n",
       " 'X_points_path': 'models/X_points.pkl',\n",
       " 'X_train_points_path': 'models/X_train_points.pkl',\n",
       " 'score_path': 'models/score_path.pkl',\n",
       " 'cutoff_score': 150,\n",
       " 'columns_': ['person_age_bin',\n",
       "  'person_income_bin',\n",
       "  'person_emp_length_bin',\n",
       "  'loan_amnt_bin',\n",
       "  'loan_int_rate_bin',\n",
       "  'loan_percent_income_bin',\n",
       "  'cb_person_cred_hist_length_bin',\n",
       "  'person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function `forward()` to fit a model on the train set and calculate its CV score from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform forward selection procedure\n",
    "def forward(X, y, predictors, scoring='roc_auc', cv=5):\n",
    "    \"\"\"Function to perform forward selection procedure\"\"\"\n",
    "\n",
    "    # Define sample size and  number of all predictors\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    # Define list of all predictors\n",
    "    col_list = np.arange(n_predictors)\n",
    "\n",
    "    # Define remaining predictors for each k\n",
    "    remaining_predictors = [p for p in col_list if p not in predictors]\n",
    "\n",
    "    # Initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Cross validate each possible combination of remaining predictors\n",
    "    for p in remaining_predictors:\n",
    "        combi = predictors + [p]\n",
    "\n",
    "        # Extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Define the estimator\n",
    "        model = LogisticRegression(penalty = None,\n",
    "                                   class_weight = 'balanced')\n",
    "\n",
    "        # Cross validate the recall scores of the model\n",
    "        cv_results = cross_validate(estimator = model,\n",
    "                                    X = X_,\n",
    "                                    y = y_,\n",
    "                                    scoring = scoring,\n",
    "                                    cv = cv)\n",
    "\n",
    "        # Calculate the average CV/recall score\n",
    "        score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "        # Append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                           \"CV Score\": score_list})\n",
    "\n",
    "    # Choose the best model\n",
    "    best_model = models.loc[models['CV Score'].argmax()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform forward selection on all characteristics\n",
    "def run_forward():\n",
    "    \"\"\"Function to perform forward selection on all characteristics\"\"\"\n",
    "\n",
    "    cv = CONFIG_DATA['num_of_cv']\n",
    "    scoring = CONFIG_DATA['scoring']\n",
    "\n",
    "    X_train_woe_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_woe_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    # First, fit the null model\n",
    "    # Define predictor for the null model\n",
    "    predictor = []\n",
    "\n",
    "    # The predictor in the null model is zero values for all predictors\n",
    "    X_null = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "    # Define the estimator\n",
    "    model = LogisticRegression(penalty = None,\n",
    "                               class_weight = 'balanced')\n",
    "\n",
    "    # Cross validate\n",
    "    cv_results = cross_validate(estimator = model,\n",
    "                                X = X_null,\n",
    "                                y = y_train,\n",
    "                                cv = cv,\n",
    "                                scoring = scoring)\n",
    "\n",
    "    # Calculate the average CV score\n",
    "    score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "    # Create table for the best model of each k predictors\n",
    "    # Append the results of null model\n",
    "    forward_models = pd.DataFrame({\"Predictors\": [predictor],\n",
    "                                   \"CV Score\": [score_]})\n",
    "\n",
    "    # Next, perform forward selection for all predictors\n",
    "    # Define list of predictors\n",
    "    predictors = []\n",
    "    n_predictors = X_train.shape[1]\n",
    "\n",
    "    # Perform forward selection procedure for k=1,...,n_predictors\n",
    "    for k in range(n_predictors):\n",
    "        _, best_model = forward(X = X_train,\n",
    "                                y = y_train,\n",
    "                                predictors = predictors,\n",
    "                                scoring = scoring,\n",
    "                                cv = cv)\n",
    "\n",
    "        # Tabulate the best model of each k predictors\n",
    "        forward_models.loc[k+1] = best_model\n",
    "        predictors = best_model['Predictors']\n",
    "\n",
    "    # Find the best CV score\n",
    "    best_idx = forward_models['CV Score'].argmax()\n",
    "    best_cv_score = forward_models['CV Score'].loc[best_idx]\n",
    "    best_predictors = forward_models['Predictors'].loc[best_idx]\n",
    "\n",
    "    # Print the summary\n",
    "    print('===================================================')\n",
    "    print('Best index            :', best_idx)\n",
    "    print('Best CV Score         :', best_cv_score)\n",
    "    print('Best predictors (idx) :', best_predictors)\n",
    "    print('Best predictors       :')\n",
    "    print(X_train_woe.columns[best_predictors].tolist())\n",
    "    print('===================================================')\n",
    "\n",
    "    print(forward_models)\n",
    "    print('===================================================')\n",
    "    \n",
    "    forward_models_path = CONFIG_DATA['forward_models_path']\n",
    "    utils.pickle_dump(forward_models, forward_models_path)\n",
    "\n",
    "    best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "    utils.pickle_dump(best_predictors, best_predictors_path)\n",
    "\n",
    "    return forward_models, best_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/output/X_train_woe.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Axel\\Desktop\\Data Science\\credit_scoring\\example\\5. modeling.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run the function\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m run_forward()\n",
      "\u001b[1;32mc:\\Users\\Axel\\Desktop\\Data Science\\credit_scoring\\example\\5. modeling.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m scoring \u001b[39m=\u001b[39m CONFIG_DATA[\u001b[39m'\u001b[39m\u001b[39mscoring\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train_woe_path \u001b[39m=\u001b[39m CONFIG_DATA[\u001b[39m'\u001b[39m\u001b[39mX_train_woe_path\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train_woe \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mpickle_load(X_train_woe_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_train_woe\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Axel/Desktop/Data%20Science/credit_scoring/example/5.%20modeling.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_train_path \u001b[39m=\u001b[39m CONFIG_DATA[\u001b[39m'\u001b[39m\u001b[39mtrain_path\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Axel\\Desktop\\Data Science\\credit_scoring\\example\\src\\utils.py:16\u001b[0m, in \u001b[0;36mpickle_load\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpickle_load\u001b[39m(file_path):\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\"\"Function to load pickle files\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m joblib\u001b[39m.\u001b[39;49mload(file_path)\n",
      "File \u001b[1;32mc:\\Users\\Axel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    577\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    578\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    580\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/output/X_train_woe.pkl'"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "run_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit the best model on whole X_train\n",
    "def best_model_fitting(best_predictors):\n",
    "    \"\"\"Function to fit best model on whole X_train\"\"\"\n",
    "\n",
    "    X_train_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.pickle_load(X_train_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.pickle_load(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    if best_predictors is None:\n",
    "        best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "        best_predictors = utils.pickle_load(best_predictors_path)\n",
    "        print(f\"Best predictors index   :\", best_predictors)\n",
    "    else:\n",
    "        print(f\"[Adjusted] best predictors index   :\", best_predictors)\n",
    "\n",
    "    # Define X with best predictors\n",
    "    X_train_best = X_train[:, best_predictors]\n",
    "\n",
    "    # Fit best model\n",
    "    best_model = LogisticRegression(penalty = None,\n",
    "                                    class_weight = 'balanced')\n",
    "    best_model.fit(X_train_best, y_train)\n",
    "\n",
    "    print(best_model)\n",
    "\n",
    "    # Extract the best model' parameter estimates\n",
    "    best_model_intercept = pd.DataFrame({'Characteristic': 'Intercept',\n",
    "                                         'Estimate': best_model.intercept_})\n",
    "    \n",
    "    best_model_params = X_train_woe.columns[best_predictors].tolist()\n",
    "\n",
    "    best_model_coefs = pd.DataFrame({'Characteristic': best_model_params,\n",
    "                                     'Estimate': np.reshape(best_model.coef_, \n",
    "                                                            len(best_predictors))})\n",
    "\n",
    "    best_model_summary = pd.concat((best_model_intercept, best_model_coefs),\n",
    "                                   axis = 0,\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    print('===================================================')\n",
    "    print(best_model_summary)\n",
    "    \n",
    "    best_model_path = CONFIG_DATA['best_model_path']\n",
    "    utils.pickle_dump(best_model, best_model_path)\n",
    "\n",
    "    best_model_summary_path = CONFIG_DATA['best_model_summary_path']\n",
    "    utils.pickle_dump(best_model_summary, best_model_summary_path)\n",
    "\n",
    "    return best_model, best_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best predictors index   : [2, 9]\n",
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "              Characteristic  Estimate\n",
      "0                  Intercept  0.000216\n",
      "1      person_home_ownership -0.996248\n",
      "2  cb_person_default_on_file -0.991864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "               Characteristic  Estimate\n",
       " 0                  Intercept  0.000216\n",
       " 1      person_home_ownership -0.996248\n",
       " 2  cb_person_default_on_file -0.991864)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the function\n",
    "best_model_fitting(best_predictors = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Model Adjustment**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scorecards with too few characteristics are generally unable to withstand the test of time:\n",
    "  - They are susceptible to minor changes in the applicant profile.\n",
    "  - A good adjudicator will never look at just two characteristics from an application form to make a decision.\n",
    "\n",
    "We will include all characteristics in the final model.\n",
    "  - From the independence test, all characteristics are not independent of the response variable (probability of default).\n",
    "  - Generally, a final scorecards consist of between 8 and 15 characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adjusted] best predictors index   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(class_weight='balanced', penalty=None)\n",
      "===================================================\n",
      "                Characteristic  Estimate\n",
      "0                    Intercept -0.059463\n",
      "1                   person_age -0.057122\n",
      "2                person_income -0.977773\n",
      "3        person_home_ownership -0.749994\n",
      "4            person_emp_length -0.249803\n",
      "5                  loan_intent -1.252916\n",
      "6                   loan_grade -1.156946\n",
      "7                    loan_amnt -0.855171\n",
      "8                loan_int_rate  0.008703\n",
      "9          loan_percent_income -0.765774\n",
      "10   cb_person_default_on_file  0.017819\n",
      "11  cb_person_cred_hist_length -0.569405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced', penalty=None),\n",
       "                 Characteristic  Estimate\n",
       " 0                    Intercept -0.059463\n",
       " 1                   person_age -0.057122\n",
       " 2                person_income -0.977773\n",
       " 3        person_home_ownership -0.749994\n",
       " 4            person_emp_length -0.249803\n",
       " 5                  loan_intent -1.252916\n",
       " 6                   loan_grade -1.156946\n",
       " 7                    loan_amnt -0.855171\n",
       " 8                loan_int_rate  0.008703\n",
       " 9          loan_percent_income -0.765774\n",
       " 10   cb_person_default_on_file  0.017819\n",
       " 11  cb_person_cred_hist_length -0.569405)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust the best predictors\n",
    "best_model_fitting(best_predictors = np.arange(11).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
