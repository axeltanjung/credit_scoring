{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Modeling**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform:\n",
    "1. Forward Selection Procedure\n",
    "2. Best Model Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform Forward Selection Procedure**\n",
    "---\n",
    "Start with a null model (no predictors), then add each predictor one at a time until the model is as improved as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import library for modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load configuration\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_path': 'data/raw/credit_dataset.csv',\n",
       " 'data_path': 'data/output/data.pkl',\n",
       " 'predictors_set_path': 'data/output/predictors.pkl',\n",
       " 'target_set_path': 'data/output/target.pkl',\n",
       " 'train_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'test_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'data_train_path': 'data/output/data_train.pkl',\n",
       " 'data_train_binned_path': 'data/output/data_train_binned.pkl',\n",
       " 'crosstab_list_path': 'data/output/crosstab_list.pkl',\n",
       " 'WOE_table_path': 'data/output/WOE_table.pkl',\n",
       " 'IV_table_path': 'data/output/IV_table.pkl',\n",
       " 'WOE_map_dict_path': 'data/output/WOE_map_dict.pkl',\n",
       " 'X_train_woe_path': 'data/output/X_train_woe.pkl',\n",
       " 'target_variable': 'Credit_Score',\n",
       " 'test_size': 0.3,\n",
       " 'num_columns': ['Age',\n",
       "  'Annual_Income',\n",
       "  'Num_of_Loan',\n",
       "  'Num_of_Delayed_Payment',\n",
       "  'Outstanding_Debt',\n",
       "  'Monthly_Inhand_Salary',\n",
       "  'Num_Credit_Inquiries',\n",
       "  'Credit_Utilization_Ratio',\n",
       "  'Total_EMI_per_month',\n",
       "  'Num_Bank_Accounts',\n",
       "  'Num_Credit_Card',\n",
       "  'Interest_Rate',\n",
       "  'Delay_from_due_date',\n",
       "  'Amount_invested_monthly',\n",
       "  'Monthly_Balance',\n",
       "  'Changed_Credit_Limit',\n",
       "  'Credit_History_Age'],\n",
       " 'cat_columns': ['Occupation',\n",
       "  'Type_of_Loan',\n",
       "  'Credit_Mix',\n",
       "  'Payment_of_Min_Amount',\n",
       "  'Payment_Behaviour'],\n",
       " 'missing_columns': ['Age_bin',\n",
       "  'Num_Bank_Accounts_bin',\n",
       "  'Num_Credit_Card_bin',\n",
       "  'Interest_Rate_bin',\n",
       "  'Num_of_Loan_bin',\n",
       "  'Num_of_Delayed_Payment_bin',\n",
       "  'Num_Credit_Inquiries_bin',\n",
       "  'Monthly_Balance_bin'],\n",
       " 'num_of_bins': 4,\n",
       " 'num_of_cv': 10,\n",
       " 'scoring': 'recall',\n",
       " 'forward_models_path': 'models/forward_models.pkl',\n",
       " 'best_predictors_path': 'models/best_predictors_path.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_model_summary_path': 'models/best_model_summary.pkl',\n",
       " 'pdo': 20,\n",
       " 'score_ref': 300,\n",
       " 'odds_ref': 30,\n",
       " 'scorecards_path': 'models/scorecards.pkl',\n",
       " 'points_map_dict_path': 'models/points_map_dict.pkl',\n",
       " 'X_points_path': 'models/X_points.pkl',\n",
       " 'X_train_points_path': 'models/X_train_points.pkl',\n",
       " 'score_path': 'models/score_path.pkl',\n",
       " 'cutoff_score': 150,\n",
       " 'columns_': ['person_age_bin',\n",
       "  'person_income_bin',\n",
       "  'person_emp_length_bin',\n",
       "  'loan_amnt_bin',\n",
       "  'loan_int_rate_bin',\n",
       "  'loan_percent_income_bin',\n",
       "  'cb_person_cred_hist_length_bin',\n",
       "  'person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.load_config()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a model on the train set and determine its CV score from the validation set, define the function `forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The forward selection procedure's function\n",
    "def forward(X, y, predictors, scoring='roc_auc', cv=5):\n",
    "    \"\"\"Function for carrying out the forward selection process\"\"\"\n",
    "\n",
    "    # Specify the number of all predictors and the sample size.\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    # Describe the entire predictor list.\n",
    "    col_list = np.arange(n_predictors)\n",
    "\n",
    "    # For every k, define the remaining predictors.\n",
    "    remaining_predictors = [p for p in col_list if p not in predictors]\n",
    "\n",
    "    # Set the CV Score and predictors' initial values.\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Every possible pairing of the remaining predictors should be cross-validated.\n",
    "    for p in remaining_predictors:\n",
    "        combi = predictors + [p]\n",
    "\n",
    "        # Combine extract predictors\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Define the estimator\n",
    "        model = LogisticRegression(penalty = 'l2',\n",
    "                                   class_weight = 'balanced')\n",
    "\n",
    "        # Cross-validate the model's recall scores\n",
    "        cv_results = cross_validate(estimator = model,\n",
    "                                    X = X_,\n",
    "                                    y = y_,\n",
    "                                    scoring = scoring,\n",
    "                                    cv = cv)\n",
    "\n",
    "        # Determine the typical CV/recall score.\n",
    "        score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "        # Add the combination of predictors and their CV score to the list.\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Total the outcomes.\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                           \"CV Score\": score_list})\n",
    "\n",
    "    # Select the best model.\n",
    "    best_model = models.loc[models['CV Score'].argmax()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ability to carry out forward selection across all attributes\n",
    "def run_forward():\n",
    "    \"\"\"Function to carry out forward selection based on every attribute\"\"\"\n",
    "\n",
    "    cv = CONFIG_DATA['num_of_cv']\n",
    "    scoring = CONFIG_DATA['scoring']\n",
    "\n",
    "    X_train_woe_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.load_pickle(X_train_woe_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.load_pickle(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    # First, fit the null model\n",
    "    # Define the null model's predictor.\n",
    "    predictor = []\n",
    "\n",
    "    # In the null model, every predictor has a value of zero.\n",
    "    X_null = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "    # Define the estimator\n",
    "    model = LogisticRegression(penalty = 'l2',\n",
    "                               class_weight = 'balanced')\n",
    "\n",
    "    # Cross validate\n",
    "    cv_results = cross_validate(estimator = model,\n",
    "                                X = X_null,\n",
    "                                y = y_train,\n",
    "                                cv = cv,\n",
    "                                scoring = scoring)\n",
    "\n",
    "    # Determine the typical CV score.\n",
    "    score_ = np.mean(cv_results['test_score'])\n",
    "\n",
    "    # Make a table with each k predictor's best model.\n",
    "    # Add the null model results.\n",
    "    forward_models = pd.DataFrame({\"Predictors\": [predictor],\n",
    "                                   \"CV Score\": [score_]})\n",
    "\n",
    "    # Proceed with forward selection for each and every predictor.\n",
    "    # Define the predictor list.\n",
    "    predictors = []\n",
    "    n_predictors = X_train.shape[1]\n",
    "\n",
    "    # Apply the forward selection method to the predictors k=1,...,n_predictors.\n",
    "    for k in range(n_predictors):\n",
    "        _, best_model = forward(X = X_train,\n",
    "                                y = y_train,\n",
    "                                predictors = predictors,\n",
    "                                scoring = scoring,\n",
    "                                cv = cv)\n",
    "\n",
    "        # List the optimal model for each of the k predictors.\n",
    "        forward_models.loc[k+1] = best_model\n",
    "        predictors = best_model['Predictors']\n",
    "\n",
    "    # Find the best CV score\n",
    "    best_idx = forward_models['CV Score'].argmax()\n",
    "    best_cv_score = forward_models['CV Score'].loc[best_idx]\n",
    "    best_predictors = forward_models['Predictors'].loc[best_idx]\n",
    "\n",
    "    # Print the summary\n",
    "    print('===================================================')\n",
    "    print('Best index            :', best_idx)\n",
    "    print('Best CV Score         :', best_cv_score)\n",
    "    print('Best predictors (idx) :', best_predictors)\n",
    "    print('Best predictors       :')\n",
    "    print(X_train_woe.columns[best_predictors].tolist())\n",
    "    print('===================================================')\n",
    "\n",
    "    print(forward_models)\n",
    "    print('===================================================')\n",
    "    \n",
    "    forward_models_path = CONFIG_DATA['forward_models_path']\n",
    "    utils.dump_pickle(forward_models, forward_models_path)\n",
    "\n",
    "    best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "    utils.dump_pickle(best_predictors, best_predictors_path)\n",
    "\n",
    "    return forward_models, best_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Best index            : 2\n",
      "Best CV Score         : 0.9114868456019133\n",
      "Best predictors (idx) : [11, 5]\n",
      "Best predictors       :\n",
      "['Changed_Credit_Limit', 'Num_Credit_Card']\n",
      "===================================================\n",
      "                                           Predictors  CV Score\n",
      "0                                                  []  0.000000\n",
      "1                                                [11]  0.874289\n",
      "2                                             [11, 5]  0.911487\n",
      "3                                         [11, 5, 15]  0.902549\n",
      "4                                     [11, 5, 15, 18]  0.882310\n",
      "5                                  [11, 5, 15, 18, 6]  0.856865\n",
      "6                              [11, 5, 15, 18, 6, 14]  0.895473\n",
      "7                           [11, 5, 15, 18, 6, 14, 7]  0.895943\n",
      "8                       [11, 5, 15, 18, 6, 14, 7, 21]  0.895945\n",
      "9                    [11, 5, 15, 18, 6, 14, 7, 21, 8]  0.897358\n",
      "10               [11, 5, 15, 18, 6, 14, 7, 21, 8, 20]  0.895945\n",
      "11           [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19]  0.895004\n",
      "12        [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3]  0.894528\n",
      "13     [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2]  0.892648\n",
      "14  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2, 0]  0.890759\n",
      "15  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.887475\n",
      "16  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.883705\n",
      "17  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.877580\n",
      "18  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.875704\n",
      "19  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.870520\n",
      "20  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.867690\n",
      "21  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.862038\n",
      "22  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.822024\n",
      "===================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                           Predictors  CV Score\n",
       " 0                                                  []  0.000000\n",
       " 1                                                [11]  0.874289\n",
       " 2                                             [11, 5]  0.911487\n",
       " 3                                         [11, 5, 15]  0.902549\n",
       " 4                                     [11, 5, 15, 18]  0.882310\n",
       " 5                                  [11, 5, 15, 18, 6]  0.856865\n",
       " 6                              [11, 5, 15, 18, 6, 14]  0.895473\n",
       " 7                           [11, 5, 15, 18, 6, 14, 7]  0.895943\n",
       " 8                       [11, 5, 15, 18, 6, 14, 7, 21]  0.895945\n",
       " 9                    [11, 5, 15, 18, 6, 14, 7, 21, 8]  0.897358\n",
       " 10               [11, 5, 15, 18, 6, 14, 7, 21, 8, 20]  0.895945\n",
       " 11           [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19]  0.895004\n",
       " 12        [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3]  0.894528\n",
       " 13     [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2]  0.892648\n",
       " 14  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2, 0]  0.890759\n",
       " 15  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.887475\n",
       " 16  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.883705\n",
       " 17  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.877580\n",
       " 18  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.875704\n",
       " 19  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.870520\n",
       " 20  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.867690\n",
       " 21  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.862038\n",
       " 22  [11, 5, 15, 18, 6, 14, 7, 21, 8, 20, 19, 3, 2,...  0.822024,\n",
       " [11, 5])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit optimal model across the entire X_train\n",
    "def best_model_fitting(best_predictors):\n",
    "    \"\"\"Function to fit optimal model across the entire X_train\"\"\"\n",
    "\n",
    "    X_train_path = CONFIG_DATA['X_train_woe_path']\n",
    "    X_train_woe = utils.load_pickle(X_train_path)\n",
    "    X_train = X_train_woe.to_numpy()\n",
    "\n",
    "    y_train_path = CONFIG_DATA['train_path'][1]\n",
    "    y_train = utils.load_pickle(y_train_path)\n",
    "    y_train = y_train.to_numpy()\n",
    "\n",
    "    if best_predictors is None:\n",
    "        best_predictors_path = CONFIG_DATA['best_predictors_path']\n",
    "        best_predictors = utils.load_pickle(best_predictors_path)\n",
    "        print(f\"Best predictors index   :\", best_predictors)\n",
    "    else:\n",
    "        print(f\"[Adjusted] best predictors index   :\", best_predictors)\n",
    "\n",
    "    # Use the best predictors to define X.\n",
    "    X_train_best = X_train[:, best_predictors]\n",
    "\n",
    "    # Fit best model\n",
    "    best_model = LogisticRegression(penalty = 'l2',\n",
    "                                    class_weight = 'balanced')\n",
    "    best_model.fit(X_train_best, y_train)\n",
    "\n",
    "    print(best_model)\n",
    "\n",
    "    # Extract parameter estimates from the optimal model.\n",
    "    best_model_intercept = pd.DataFrame({'Characteristic': 'Intercept',\n",
    "                                         'Estimate': best_model.intercept_})\n",
    "    \n",
    "    best_model_params = X_train_woe.columns[best_predictors].tolist()\n",
    "\n",
    "    best_model_coefs = pd.DataFrame({'Characteristic': best_model_params,\n",
    "                                     'Estimate': np.reshape(best_model.coef_, \n",
    "                                                            len(best_predictors))})\n",
    "\n",
    "    best_model_summary = pd.concat((best_model_intercept, best_model_coefs),\n",
    "                                   axis = 0,\n",
    "                                   ignore_index = True)\n",
    "    \n",
    "    print('===================================================')\n",
    "    print(best_model_summary)\n",
    "    \n",
    "    best_model_path = CONFIG_DATA['best_model_path']\n",
    "    utils.dump_pickle(best_model, best_model_path)\n",
    "\n",
    "    best_model_summary_path = CONFIG_DATA['best_model_summary_path']\n",
    "    utils.dump_pickle(best_model_summary, best_model_summary_path)\n",
    "\n",
    "    return best_model, best_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best predictors index   : [11, 5]\n",
      "LogisticRegression(class_weight='balanced')\n",
      "===================================================\n",
      "         Characteristic  Estimate\n",
      "0             Intercept -0.004195\n",
      "1  Changed_Credit_Limit  0.777330\n",
      "2       Num_Credit_Card  0.940723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced'),\n",
       "          Characteristic  Estimate\n",
       " 0             Intercept -0.004195\n",
       " 1  Changed_Credit_Limit  0.777330\n",
       " 2       Num_Credit_Card  0.940723)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_fitting(best_predictors = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Model Adjustment**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too-simple scorecards typically cannot stand the test of time because: \n",
    "- They are easily affected by slight alterations in the applicant profile.\n",
    "- An adjudicator of quality would never base their decision on merely two features from an application form.\n",
    "\n",
    "Every feature will be present in the finished model.\n",
    "- The independence test indicates that no attribute is independent of the response variable (default probability).\n",
    "- Typically, a final scorecard has eight to fifteen characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adjusted] best predictors index   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LogisticRegression(class_weight='balanced')\n",
      "===================================================\n",
      "            Characteristic  Estimate\n",
      "0                Intercept -0.048574\n",
      "1                      Age  0.266541\n",
      "2               Occupation  0.944933\n",
      "3            Annual_Income  0.110433\n",
      "4    Monthly_Inhand_Salary  0.061898\n",
      "5        Num_Bank_Accounts  0.184315\n",
      "6          Num_Credit_Card  0.342532\n",
      "7            Interest_Rate  0.514895\n",
      "8              Num_of_Loan  0.285725\n",
      "9             Type_of_Loan -0.066199\n",
      "10     Delay_from_due_date  0.370126\n",
      "11  Num_of_Delayed_Payment  0.226606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(class_weight='balanced'),\n",
       "             Characteristic  Estimate\n",
       " 0                Intercept -0.048574\n",
       " 1                      Age  0.266541\n",
       " 2               Occupation  0.944933\n",
       " 3            Annual_Income  0.110433\n",
       " 4    Monthly_Inhand_Salary  0.061898\n",
       " 5        Num_Bank_Accounts  0.184315\n",
       " 6          Num_Credit_Card  0.342532\n",
       " 7            Interest_Rate  0.514895\n",
       " 8              Num_of_Loan  0.285725\n",
       " 9             Type_of_Loan -0.066199\n",
       " 10     Delay_from_due_date  0.370126\n",
       " 11  Num_of_Delayed_Payment  0.226606)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_fitting(best_predictors = np.arange(11).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
